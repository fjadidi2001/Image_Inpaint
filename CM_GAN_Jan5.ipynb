{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHnvHFpcugfYnHdsZEbIU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Image_Inpaint/blob/main/CM_GAN_Jan5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The architecture of CM-GAN focuses on image inpainting, specifically designed to fill in missing or corrupted regions of images with realistic content. While\n",
        "### **1. Generator Architecture**\n",
        "The generator is responsible for creating realistic inpainted images. CM-GAN uses **cascaded modulation** to process inputs. A common flow:\n",
        "\n",
        "#### Input:\n",
        "- An **image** with missing regions (masked image).\n",
        "- A **binary mask** representing the missing areas (1 for missing, 0 for existing pixels).\n",
        "\n",
        "#### Layers:\n",
        "1. **Convolutional Layers with Mask Concatenation**:\n",
        "   - Initial layers concatenate the image with the binary mask.\n",
        "   - Convolutions extract features from the masked regions.\n",
        "\n",
        "   **Purpose**: Learn the structure and surrounding context of the image.\n",
        "\n",
        "2. **Cascaded Modulation Block**:\n",
        "   - Combines **global modulation** (to understand overall image semantics) with **spatially adaptive modulation** (to handle local details).\n",
        "   - Global modulation uses a feature map that spans the entire image.\n",
        "   - Adaptive modulation applies location-specific adjustments.\n",
        "\n",
        "   **Purpose**: Balance global coherence and local realism.\n",
        "\n",
        "3. **Feature Propagation via Attention Mechanisms**:\n",
        "   - **Enhanced Attention** to propagate contextual information from known to unknown areas.\n",
        "\n",
        "   **Purpose**: Ensures accurate filling of missing regions based on surrounding context.\n",
        "\n",
        "4. **Output Layers**:\n",
        "   - A final set of convolutions or deconvolutions reconstructs the inpainted image.\n",
        "\n",
        "   **Purpose**: Generate the final high-quality inpainted output.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. Discriminator Architecture**\n",
        "The discriminator evaluates the inpainted images for realism.\n",
        "\n",
        "1. **Input**:\n",
        "   - The inpainted image (from the generator).\n",
        "   - The corresponding ground truth image (actual image without missing areas).\n",
        "\n",
        "2. **Layers**:\n",
        "   - Convolutional layers extract features.\n",
        "   - Outputs a **realism score**, indicating how realistic the inpainted image is.\n",
        "\n",
        "3. **Loss Function**:\n",
        "   - Often uses an **adversarial loss** (e.g., Wasserstein or hinge loss) to train the generator and discriminator in a competitive manner.\n",
        "\n",
        "---\n",
        "\n",
        "### **Key Components of CM-GAN**\n",
        "1. **Object-Aware Training**:\n",
        "   - Focuses on challenging regions, like objects, using annotations (e.g., panoptic segmentation).\n",
        "   - Ensures that the generator fills object regions more realistically.\n",
        "\n",
        "2. **Mask-Aware Encoding**:\n",
        "   - Explicitly considers the mask during feature extraction.\n",
        "   - Helps the generator learn to handle varied mask sizes and shapes.\n",
        "\n",
        "3. **Enhanced Attention**:\n",
        "   - Propagates information from visible areas to missing areas.\n",
        "   - Improves inpainting quality for complex patterns.\n",
        "\n",
        "---\n",
        "\n",
        "### **How the Architecture Works**\n",
        "1. **Training**:\n",
        "   - The generator creates inpainted images.\n",
        "   - The discriminator evaluates their realism.\n",
        "   - Both networks are updated iteratively to improve their performance.\n",
        "\n",
        "2. **Inference**:\n",
        "   - Given an input image and a mask, the generator fills the missing regions.\n",
        "   - No discriminator is needed during inference.\n"
      ],
      "metadata": {
        "id": "qSeics-fhrmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Gather the Dataset\n"
      ],
      "metadata": {
        "id": "D5Wl0pJ4jriZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://data.csail.mit.edu/places/places365/train_large_places365standard.tar\n"
      ],
      "metadata": {
        "id": "vA6ohVVspUws",
        "outputId": "42ff7276-b1f7-4886-c04f-61bfce1ffcb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-05 18:08:34--  http://data.csail.mit.edu/places/places365/train_large_places365standard.tar\n",
            "Resolving data.csail.mit.edu (data.csail.mit.edu)... 128.52.131.233\n",
            "Connecting to data.csail.mit.edu (data.csail.mit.edu)|128.52.131.233|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://data.csail.mit.edu/places/places365/train_large_places365standard.tar [following]\n",
            "--2025-01-05 18:08:35--  https://data.csail.mit.edu/places/places365/train_large_places365standard.tar\n",
            "Connecting to data.csail.mit.edu (data.csail.mit.edu)|128.52.131.233|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 112598435840 (105G) [application/x-tar]\n",
            "Saving to: ‘train_large_places365standard.tar’\n",
            "\n",
            "   train_large_plac   1%[                    ]   1.27G  15.4MB/s    eta 1h 57m "
          ]
        }
      ]
    }
  ]
}