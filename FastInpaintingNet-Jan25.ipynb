{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Image_Inpaint/blob/main/FastInpaintingNet-Jan25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "-yLDJ_bRtMHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import time"
      ],
      "metadata": {
        "id": "wQlqib31tGSC"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- torch: PyTorch library for tensor operations and neural networks.\n",
        "\n",
        "- matplotlib.pyplot: For plotting and visualizing images.\n",
        "\n",
        "- torchvision.utils.make_grid: Utility to create a grid of images.\n",
        "\n",
        "- numpy: For numerical operations.\n",
        "\n",
        "- skimage.metrics: For calculating image quality metrics like SSIM and PSNR.\n",
        "\n",
        "- time: For measuring inference time."
      ],
      "metadata": {
        "id": "7xyS_6PLtj7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Denormalize Function"
      ],
      "metadata": {
        "id": "sPrCqOAxt9ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize(tensor):\n",
        "    \"\"\"Denormalize the tensor from [-1,1] to [0,1] range\"\"\"\n",
        "    tensor = tensor.clone()\n",
        "    mean = torch.tensor([0.5, 0.5, 0.5]).view(-1, 1, 1).to(tensor.device)\n",
        "    std = torch.tensor([0.5, 0.5, 0.5]).view(-1, 1, 1).to(tensor.device)\n",
        "    return torch.clamp(tensor * std + mean, 0, 1)"
      ],
      "metadata": {
        "id": "o_Cvg1eYtg1P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Converts normalized tensors (with values in the range [-1, 1]) back to the original range [0, 1].\n",
        "\n",
        "Steps:\n",
        "\n",
        "- Clone the tensor to avoid modifying the original.\n",
        "\n",
        "- Define mean and standard deviation tensors.\n",
        "\n",
        "- Apply the denormalization formula: tensor = (tensor * std) + mean.\n",
        "\n",
        "- Clamp the values to ensure they stay within [0, 1]."
      ],
      "metadata": {
        "id": "v43uZu5IuBy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Evaluate and Visualize Function\n"
      ],
      "metadata": {
        "id": "2ZyO0BoIuo_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_visualize(model, test_loader, device, num_samples=8, save_path='inpainting_results.png'):\n",
        "    \"\"\"\n",
        "    Evaluate the model and create detailed visualizations of the results\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Lists to store metrics\n",
        "    psnr_scores = []\n",
        "    ssim_scores = []\n",
        "    inference_times = []\n",
        "\n",
        "    # Get a batch of test images\n",
        "    batch = next(iter(test_loader))\n",
        "    images = batch[0][:num_samples].to(device)\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(4, num_samples, figsize=(20, 16))\n",
        "    plt.suptitle('Inpainting Results', fontsize=16)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Process each image\n",
        "        for i in range(num_samples):\n",
        "            # Original image\n",
        "            original = denormalize(images[i])\n",
        "            axes[0, i].imshow(original.cpu().permute(1, 2, 0))\n",
        "            axes[0, i].axis('off')\n",
        "            if i == 0:\n",
        "                axes[0, i].set_title('Original')\n",
        "\n",
        "            # Create and apply mask\n",
        "            mask = create_fast_mask(original)\n",
        "            masked = original * mask\n",
        "            axes[1, i].imshow(mask.cpu().permute(1, 2, 0), cmap='gray')\n",
        "            axes[1, i].axis('off')\n",
        "            if i == 0:\n",
        "                axes[1, i].set_title('Mask')\n",
        "\n",
        "            # Masked image\n",
        "            axes[2, i].imshow(masked.cpu().permute(1, 2, 0))\n",
        "            axes[2, i].axis('off')\n",
        "            if i == 0:\n",
        "                axes[2, i].set_title('Masked Input')\n",
        "\n",
        "            # Time the inference\n",
        "            start_time = time.time()\n",
        "            inpainted = model(masked.unsqueeze(0), mask.unsqueeze(0))\n",
        "            inference_time = time.time() - start_time\n",
        "            inference_times.append(inference_time)\n",
        "\n",
        "            # Denormalize and show inpainted result\n",
        "            inpainted = denormalize(inpainted[0])\n",
        "            axes[3, i].imshow(inpainted.cpu().permute(1, 2, 0))\n",
        "            axes[3, i].axis('off')\n",
        "            if i == 0:\n",
        "                axes[3, i].set_title('Inpainted Result')\n",
        "\n",
        "            # Calculate metrics\n",
        "            original_np = original.cpu().permute(1, 2, 0).numpy()\n",
        "            inpainted_np = inpainted.cpu().permute(1, 2, 0).numpy()\n",
        "\n",
        "            psnr_score = psnr(original_np, inpainted_np)\n",
        "            ssim_score = ssim(original_np, inpainted_np, channel_axis=2, data_range=1.0)\n",
        "\n",
        "            psnr_scores.append(psnr_score)\n",
        "            ssim_scores.append(ssim_score)\n",
        "\n",
        "            # Add metrics as text under the image\n",
        "            axes[3, i].text(0.5, -0.2, f'PSNR: {psnr_score:.1f}\\nSSIM: {ssim_score:.3f}',\n",
        "                          ha='center', transform=axes[3, i].transAxes)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Print detailed evaluation results\n",
        "    print(\"\\n=== Inpainting Model Evaluation ===\")\n",
        "    print(f\"\\nImage Quality Metrics (averaged over {num_samples} samples):\")\n",
        "    print(f\"PSNR: {np.mean(psnr_scores):.2f} dB (±{np.std(psnr_scores):.2f})\")\n",
        "    print(f\"SSIM: {np.mean(ssim_scores):.3f} (±{np.std(ssim_scores):.3f})\")\n",
        "\n",
        "    print(\"\\nPerformance Metrics:\")\n",
        "    print(f\"Average inference time: {np.mean(inference_times)*1000:.1f}ms (±{np.std(inference_times)*1000:.1f}ms)\")\n",
        "\n",
        "    # Interpret results\n",
        "    print(\"\\nModel Performance Interpretation:\")\n",
        "    avg_psnr = np.mean(psnr_scores)\n",
        "    avg_ssim = np.mean(ssim_scores)\n",
        "\n",
        "    # PSNR interpretation\n",
        "    print(\"\\nPSNR Analysis:\")\n",
        "    if avg_psnr > 30:\n",
        "        print(\"✓ Excellent quality (>30 dB)\")\n",
        "    elif avg_psnr > 25:\n",
        "        print(\"✓ Good quality (25-30 dB)\")\n",
        "    else:\n",
        "        print(\"⚠ Fair to poor quality (<25 dB)\")\n",
        "\n",
        "    # SSIM interpretation\n",
        "    print(\"\\nSSIM Analysis:\")\n",
        "    if avg_ssim > 0.90:\n",
        "        print(\"✓ Excellent structural similarity (>0.90)\")\n",
        "    elif avg_ssim > 0.80:\n",
        "        print(\"✓ Good structural similarity (0.80-0.90)\")\n",
        "    else:\n",
        "        print(\"⚠ Fair to poor structural similarity (<0.80)\")\n",
        "\n",
        "    # Speed interpretation\n",
        "    avg_time = np.mean(inference_times) * 1000\n",
        "    print(\"\\nSpeed Analysis:\")\n",
        "    if avg_time < 50:\n",
        "        print(\"✓ Very fast (<50ms)\")\n",
        "    elif avg_time < 100:\n",
        "        print(\"✓ Fast (50-100ms)\")\n",
        "    else:\n",
        "        print(\"⚠ Moderate to slow (>100ms)\")\n",
        "\n",
        "    return {\n",
        "        'psnr': np.mean(psnr_scores),\n",
        "        'ssim': np.mean(ssim_scores),\n",
        "        'inference_time': np.mean(inference_times)\n",
        "    }"
      ],
      "metadata": {
        "id": "NjaXpbwiuLgK"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}