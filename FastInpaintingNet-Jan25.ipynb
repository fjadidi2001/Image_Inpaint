{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Image_Inpaint/blob/main/FastInpaintingNet-Jan25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import time"
      ],
      "metadata": {
        "id": "gOhzOkJa0JU8"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InpaintingNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InpaintingNet, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder1 = nn.Sequential(\n",
        "            nn.Conv2d(6, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.encoder2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.encoder3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Middle (Bottleneck)\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        self.decoder3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.decoder2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.decoder1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Final output layer\n",
        "        self.final = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # Concatenate input image and mask\n",
        "        x = torch.cat([x, mask], dim=1)\n",
        "\n",
        "        # Encoder\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "\n",
        "        # Middle\n",
        "        m = self.middle(e3)\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        d3 = self.decoder3(m)\n",
        "        d3 = torch.cat([d3, e3], dim=1)  # Skip connection\n",
        "        d2 = self.decoder2(d3)\n",
        "        d2 = torch.cat([d2, e2], dim=1)  # Skip connection\n",
        "        d1 = self.decoder1(d2)\n",
        "        d1 = torch.cat([d1, e1], dim=1)  # Skip connection\n",
        "\n",
        "        # Final output\n",
        "        out = self.final(d1)\n",
        "        return torch.tanh(out)  # Normalize output to [-1, 1]"
      ],
      "metadata": {
        "id": "UvKhhdkY0TZz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_data(root_dir='./data', img_size=128, batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Load CIFAR-10 dataset\n",
        "    dataset = datasets.CIFAR10(root=root_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "    # Split into train, validation, and test sets\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "CFdV0EzB0YD9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_irregular_mask(image):\n",
        "    _, h, w = image.shape\n",
        "    mask = torch.ones_like(image)\n",
        "\n",
        "    # Randomly generate irregular shapes\n",
        "    for _ in range(np.random.randint(5, 10)):\n",
        "        mask_h = np.random.randint(h // 4, h // 2)\n",
        "        mask_w = np.random.randint(w // 4, w // 2)\n",
        "        top = np.random.randint(0, h - mask_h)\n",
        "        left = np.random.randint(0, w - mask_w)\n",
        "        mask[:, top:top+mask_h, left:left+mask_w] = 0\n",
        "\n",
        "    return mask"
      ],
      "metadata": {
        "id": "Z5v2hVKm0gh_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, num_epochs=20, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "    criterion_mse = nn.MSELoss()\n",
        "\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in train_loader:\n",
        "            images = batch[0].to(device)\n",
        "            masks = torch.stack([create_irregular_mask(img) for img in images]).to(device)\n",
        "            masked_images = images * masks\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(masked_images, masks)\n",
        "\n",
        "            # Combined loss\n",
        "            loss_l1 = criterion_l1(outputs, images)\n",
        "            loss_mse = criterion_mse(outputs, images)\n",
        "            loss = loss_l1 + 0.5 * loss_mse\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                images = batch[0].to(device)\n",
        "                masks = torch.stack([create_irregular_mask(img) for img in images]).to(device)\n",
        "                masked_images = images * masks\n",
        "\n",
        "                outputs = model(masked_images, masks)\n",
        "                loss = criterion_l1(outputs, images)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "        print(f'Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
        "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
        "\n",
        "        # Save best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_inpainting_model.pth')\n",
        "\n",
        "        torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "lSSiSqSC0mf1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_visualize(model, test_loader, device, num_samples=8):\n",
        "    model.eval()\n",
        "    psnr_scores = []\n",
        "    ssim_scores = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(test_loader):\n",
        "            if i >= num_samples:\n",
        "                break\n",
        "            images = batch[0].to(device)\n",
        "            masks = torch.stack([create_irregular_mask(img) for img in images]).to(device)\n",
        "            masked_images = images * masks\n",
        "\n",
        "            outputs = model(masked_images, masks)\n",
        "\n",
        "            # Denormalize images\n",
        "            images = (images + 1) / 2  # [-1, 1] -> [0, 1]\n",
        "            outputs = (outputs + 1) / 2\n",
        "\n",
        "            # Calculate PSNR and SSIM\n",
        "            for j in range(images.size(0)):\n",
        "                psnr_scores.append(psnr(images[j].cpu().numpy(), outputs[j].cpu().numpy()))\n",
        "                ssim_scores.append(ssim(images[j].cpu().numpy(), outputs[j].cpu().numpy(), channel_axis=0, data_range=1.0))\n",
        "\n",
        "            # Visualize results\n",
        "            plt.figure(figsize=(15, 5))\n",
        "            plt.subplot(1, 3, 1)\n",
        "            plt.imshow(images[0].cpu().permute(1, 2, 0))\n",
        "            plt.title('Original')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 3, 2)\n",
        "            plt.imshow(masked_images[0].cpu().permute(1, 2, 0))\n",
        "            plt.title('Masked')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(1, 3, 3)\n",
        "            plt.imshow(outputs[0].cpu().permute(1, 2, 0))\n",
        "            plt.title('Inpainted')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.show()\n",
        "\n",
        "    print(f'Average PSNR: {np.mean(psnr_scores):.2f} dB')\n",
        "    print(f'Average SSIM: {np.mean(ssim_scores):.3f}')"
      ],
      "metadata": {
        "id": "MvBEGSmt0rgt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load data\n",
        "    train_loader, val_loader, test_loader = setup_data(img_size=128, batch_size=32)\n",
        "\n",
        "    # Create and train model\n",
        "    model = InpaintingNet()\n",
        "    train_model(model, train_loader, val_loader, num_epochs=5, device=device)\n",
        "\n",
        "    # Evaluate and visualize\n",
        "    evaluate_and_visualize(model, test_loader, device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "PKpL5zjv0wHq",
        "outputId": "22b5e9f7-ebb2-4f0c-8764-cc8d2e71cc60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 49.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    }
  ]
}