{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Image_Inpaint/blob/main/FastInpaintingNet-Jan25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import Libraries"
      ],
      "metadata": {
        "id": "-yLDJ_bRtMHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "wQlqib31tGSC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Import all necessary libraries for building and training the model, handling data, and performing image operations.\n",
        "\n",
        "Key Libraries:\n",
        "\n",
        "- torch: Core PyTorch library for tensor operations and neural networks.\n",
        "\n",
        "- torch.nn: Neural network modules (e.g., layers, loss functions).\n",
        "\n",
        "- torch.optim: Optimization algorithms (e.g., Adam).\n",
        "\n",
        "- torchvision: Datasets, transforms, and utilities for image processing.\n",
        "\n",
        "- numpy: Numerical computations."
      ],
      "metadata": {
        "id": "7xyS_6PLtj7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Define the Inpainting Model\n"
      ],
      "metadata": {
        "id": "tLiVphg8xtIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FastInpaintingNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FastInpaintingNet, self).__init__()\n",
        "\n",
        "        # Encoder: Extract features from the input\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(6, 64, kernel_size=3, padding=1),  # Input channels: 6 (image + mask)\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Middle Blocks: Process features with dilated convolutions\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=2, dilation=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=2, dilation=2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Decoder: Reconstruct the inpainted image\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 3, kernel_size=3, padding=1),  # Output channels: 3 (RGB image)\n",
        "            nn.Tanh()  # Normalize output to [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # Concatenate the input image and mask along the channel dimension\n",
        "        x = torch.cat([x, mask], dim=1)\n",
        "        # Pass through the encoder, middle blocks, and decoder\n",
        "        x = self.encoder(x)\n",
        "        x = self.middle(x)\n",
        "        x = self.decoder(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "vv7DT6UXxk_P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Define a neural network for image inpainting.\n",
        "\n",
        "Key Components:\n",
        "\n",
        "- Encoder: Reduces spatial dimensions while increasing feature depth.\n",
        "\n",
        "- Middle Blocks: Use dilated convolutions to capture larger receptive fields.\n",
        "\n",
        "- Decoder: Upsamples features to reconstruct the inpainted image.\n",
        "\n",
        "- Forward Pass: Concatenates the input image and mask, processes them through the network, and outputs the inpainted image."
      ],
      "metadata": {
        "id": "-HLh8SISxzDV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Set Up the Data Pipeline\n"
      ],
      "metadata": {
        "id": "FdEr-CCTyDeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_data(root_dir='./data', img_size=128, batch_size=32):\n",
        "    \"\"\"\n",
        "    Prepare the CIFAR-10 dataset for training, validation, and testing.\n",
        "    \"\"\"\n",
        "    # Define image transformations\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),  # Resize images to the specified size\n",
        "        transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
        "    ])\n",
        "\n",
        "    # Load the CIFAR-10 dataset\n",
        "    dataset = datasets.CIFAR10(root=root_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "    # Split the dataset into train, validation, and test sets\n",
        "    total_size = len(dataset)\n",
        "    train_size = int(0.7 * total_size)  # 70% for training\n",
        "    val_size = int(0.15 * total_size)   # 15% for validation\n",
        "    test_size = total_size - train_size - val_size  # Remaining 15% for testing\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "metadata": {
        "id": "xp1RQFW7x9jw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Prepare the dataset and create data loaders for training, validation, and testing.\n",
        "\n",
        "Steps:\n",
        "\n",
        "- Define image transformations (resize, normalize, etc.).\n",
        "\n",
        "- Load the CIFAR-10 dataset.\n",
        "\n",
        "- Split the dataset into train, validation, and test sets.\n",
        "\n",
        "- Create DataLoader objects for each split."
      ],
      "metadata": {
        "id": "YUtqC4Q6yGFC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Create a Mask for Inpainting\n"
      ],
      "metadata": {
        "id": "6EEH__shyjKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_fast_mask(image):\n",
        "    \"\"\"\n",
        "    Create a rectangular mask for inpainting.\n",
        "    \"\"\"\n",
        "    _, h, w = image.shape  # Get image height and width\n",
        "    mask = torch.ones_like(image)  # Initialize mask with ones\n",
        "\n",
        "    # Define a centered rectangular region to mask out\n",
        "    mask_h = h // 3  # Mask height\n",
        "    mask_w = w // 3  # Mask width\n",
        "    top = (h - mask_h) // 2  # Top position\n",
        "    left = (w - mask_w) // 2  # Left position\n",
        "\n",
        "    # Set the rectangular region to 0 (masked area)\n",
        "    mask[:, top:top+mask_h, left:left+mask_w] = 0\n",
        "    return mask"
      ],
      "metadata": {
        "id": "KpU_cVTLyURS"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Generate a binary mask for inpainting.\n",
        "\n",
        "Steps:\n",
        "\n",
        "- Create a mask of ones with the same shape as the input image.\n",
        "\n",
        "- Define a centered rectangular region and set its values to 0 (masked area)."
      ],
      "metadata": {
        "id": "mJS5k3qQycjd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Denormalize Function"
      ],
      "metadata": {
        "id": "sPrCqOAxt9ww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def denormalize(tensor):\n",
        "    \"\"\"Denormalize the tensor from [-1,1] to [0,1] range\"\"\"\n",
        "    tensor = tensor.clone()\n",
        "    mean = torch.tensor([0.5, 0.5, 0.5]).view(-1, 1, 1).to(tensor.device)\n",
        "    std = torch.tensor([0.5, 0.5, 0.5]).view(-1, 1, 1).to(tensor.device)\n",
        "    return torch.clamp(tensor * std + mean, 0, 1)"
      ],
      "metadata": {
        "id": "o_Cvg1eYtg1P"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose: Converts normalized tensors (with values in the range [-1, 1]) back to the original range [0, 1].\n",
        "\n",
        "Steps:\n",
        "\n",
        "- Clone the tensor to avoid modifying the original.\n",
        "\n",
        "- Define mean and standard deviation tensors.\n",
        "\n",
        "- Apply the denormalization formula: tensor = (tensor * std) + mean.\n",
        "\n",
        "- Clamp the values to ensure they stay within [0, 1]."
      ],
      "metadata": {
        "id": "v43uZu5IuBy5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Evaluate and Visualize Function\n"
      ],
      "metadata": {
        "id": "2ZyO0BoIuo_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_and_visualize(model, test_loader, device, num_samples=8, save_path='inpainting_results.png'):\n",
        "    \"\"\"\n",
        "    Evaluate the model and create detailed visualizations of the results\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Lists to store metrics\n",
        "    psnr_scores = []\n",
        "    ssim_scores = []\n",
        "    inference_times = []\n",
        "\n",
        "    # Get a batch of test images\n",
        "    batch = next(iter(test_loader))\n",
        "    images = batch[0][:num_samples].to(device)\n",
        "\n",
        "    # Create figure\n",
        "    fig, axes = plt.subplots(4, num_samples, figsize=(20, 16))\n",
        "    plt.suptitle('Inpainting Results', fontsize=16)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Process each image\n",
        "        for i in range(num_samples):\n",
        "            # Original image\n",
        "            original = denormalize(images[i])\n",
        "            axes[0, i].imshow(original.cpu().permute(1, 2, 0))\n",
        "            axes[0, i].axis('off')\n",
        "            if i == 0:\n",
        "                axes[0, i].set_title('Original')\n",
        "\n",
        "            # Create and apply mask\n",
        "            mask = create_fast_mask(original)\n",
        "            masked = original * mask\n",
        "            axes[1, i].imshow(mask.cpu().permute(1, 2, 0), cmap='gray')\n",
        "            axes[1, i].axis('off')\n",
        "            if i == 0:\n",
        "                axes[1, i].set_title('Mask')\n",
        "\n",
        "            # Masked image\n",
        "            axes[2, i].imshow(masked.cpu().permute(1, 2, 0))\n",
        "            axes[2, i].axis('off')\n",
        "            if i == 0:\n",
        "                axes[2, i].set_title('Masked Input')\n",
        "\n",
        "            # Time the inference\n",
        "            start_time = time.time()\n",
        "            inpainted = model(masked.unsqueeze(0), mask.unsqueeze(0))\n",
        "            inference_time = time.time() - start_time\n",
        "            inference_times.append(inference_time)\n",
        "\n",
        "            # Denormalize and show inpainted result\n",
        "            inpainted = denormalize(inpainted[0])\n",
        "            axes[3, i].imshow(inpainted.cpu().permute(1, 2, 0))\n",
        "            axes[3, i].axis('off')\n",
        "            if i == 0:\n",
        "                axes[3, i].set_title('Inpainted Result')\n",
        "\n",
        "            # Calculate metrics\n",
        "            original_np = original.cpu().permute(1, 2, 0).numpy()\n",
        "            inpainted_np = inpainted.cpu().permute(1, 2, 0).numpy()\n",
        "\n",
        "            psnr_score = psnr(original_np, inpainted_np)\n",
        "            ssim_score = ssim(original_np, inpainted_np, channel_axis=2, data_range=1.0)\n",
        "\n",
        "            psnr_scores.append(psnr_score)\n",
        "            ssim_scores.append(ssim_score)\n",
        "\n",
        "            # Add metrics as text under the image\n",
        "            axes[3, i].text(0.5, -0.2, f'PSNR: {psnr_score:.1f}\\nSSIM: {ssim_score:.3f}',\n",
        "                          ha='center', transform=axes[3, i].transAxes)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "    # Print detailed evaluation results\n",
        "    print(\"\\n=== Inpainting Model Evaluation ===\")\n",
        "    print(f\"\\nImage Quality Metrics (averaged over {num_samples} samples):\")\n",
        "    print(f\"PSNR: {np.mean(psnr_scores):.2f} dB (±{np.std(psnr_scores):.2f})\")\n",
        "    print(f\"SSIM: {np.mean(ssim_scores):.3f} (±{np.std(ssim_scores):.3f})\")\n",
        "\n",
        "    print(\"\\nPerformance Metrics:\")\n",
        "    print(f\"Average inference time: {np.mean(inference_times)*1000:.1f}ms (±{np.std(inference_times)*1000:.1f}ms)\")\n",
        "\n",
        "    # Interpret results\n",
        "    print(\"\\nModel Performance Interpretation:\")\n",
        "    avg_psnr = np.mean(psnr_scores)\n",
        "    avg_ssim = np.mean(ssim_scores)\n",
        "\n",
        "    # PSNR interpretation\n",
        "    print(\"\\nPSNR Analysis:\")\n",
        "    if avg_psnr > 30:\n",
        "        print(\"✓ Excellent quality (>30 dB)\")\n",
        "    elif avg_psnr > 25:\n",
        "        print(\"✓ Good quality (25-30 dB)\")\n",
        "    else:\n",
        "        print(\"⚠ Fair to poor quality (<25 dB)\")\n",
        "\n",
        "    # SSIM interpretation\n",
        "    print(\"\\nSSIM Analysis:\")\n",
        "    if avg_ssim > 0.90:\n",
        "        print(\"✓ Excellent structural similarity (>0.90)\")\n",
        "    elif avg_ssim > 0.80:\n",
        "        print(\"✓ Good structural similarity (0.80-0.90)\")\n",
        "    else:\n",
        "        print(\"⚠ Fair to poor structural similarity (<0.80)\")\n",
        "\n",
        "    # Speed interpretation\n",
        "    avg_time = np.mean(inference_times) * 1000\n",
        "    print(\"\\nSpeed Analysis:\")\n",
        "    if avg_time < 50:\n",
        "        print(\"✓ Very fast (<50ms)\")\n",
        "    elif avg_time < 100:\n",
        "        print(\"✓ Fast (50-100ms)\")\n",
        "    else:\n",
        "        print(\"⚠ Moderate to slow (>100ms)\")\n",
        "\n",
        "    return {\n",
        "        'psnr': np.mean(psnr_scores),\n",
        "        'ssim': np.mean(ssim_scores),\n",
        "        'inference_time': np.mean(inference_times)\n",
        "    }"
      ],
      "metadata": {
        "id": "NjaXpbwiuLgK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Purpose**: Evaluates the model's performance on a test dataset and visualizes the results.\n",
        "- **Steps**:\n",
        "  1. Set the model to evaluation mode.\n",
        "  2. Initialize lists to store metrics (PSNR, SSIM, inference times).\n",
        "  3. Load a batch of test images.\n",
        "  4. Create a figure to display the results.\n",
        "  5. For each image:\n",
        "     - Display the original image.\n",
        "     - Create and apply a mask.\n",
        "     - Display the masked image.\n",
        "     - Perform inference and measure the time taken.\n",
        "     - Display the inpainted result.\n",
        "     - Calculate PSNR and SSIM metrics.\n",
        "  6. Save and display the figure.\n",
        "  7. Print detailed evaluation results and interpret the metrics.\n",
        "\n"
      ],
      "metadata": {
        "id": "fH3oZTPcuy7W"
      }
    }
  ]
}