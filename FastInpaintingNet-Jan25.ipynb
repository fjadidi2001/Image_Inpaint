{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Image_Inpaint/blob/main/FastInpaintingNet-Jan25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "import time\n",
        "\n",
        "# Define the Model Architecture\n",
        "class InpaintingNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(InpaintingNet, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder1 = nn.Sequential(\n",
        "            nn.Conv2d(6, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.encoder2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.encoder3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Middle (Bottleneck)\n",
        "        self.middle = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder3 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 128, kernel_size=4, stride=2, padding=1),  # Output: 128 channels\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.decoder2 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.decoder1 = nn.Sequential(\n",
        "            nn.ConvTranspose2d(192, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Final output layer\n",
        "        self.final = nn.Conv2d(64, 3, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # Concatenate input image and mask\n",
        "        x = torch.cat([x, mask], dim=1)\n",
        "\n",
        "        # Encoder\n",
        "        e1 = self.encoder1(x)  # Output size: (batch, 64, H/2, W/2)\n",
        "        e2 = self.encoder2(e1)  # Output size: (batch, 128, H/4, W/4)\n",
        "        e3 = self.encoder3(e2)  # Output size: (batch, 256, H/8, W/8)\n",
        "\n",
        "        # Middle\n",
        "        m = self.middle(e3)  # Output size: (batch, 512, H/8, W/8)\n",
        "\n",
        "        # Decoder with skip connections\n",
        "        d3 = self.decoder3(m)  # Output size: (batch, 128, H/4, W/4)\n",
        "        d3 = torch.cat([d3, e2], dim=1)  # Skip connection (batch, 128 + 128, H/4, W/4)\n",
        "\n",
        "        d2 = self.decoder2(d3)  # Output size: (batch, 128, H/2, W/2)\n",
        "        d2 = torch.cat([d2, e1], dim=1)  # Skip connection (batch, 128 + 64, H/2, W/2)\n",
        "\n",
        "        d1 = self.decoder1(d2)  # Output size: (batch, 64, H, W)\n",
        "\n",
        "        # Final output\n",
        "        out = self.final(d1)  # Output size: (batch, 3, H, W)\n",
        "        return torch.tanh(out)  # Normalize output to [-1, 1]\n",
        "\n",
        "# Define VGG-based Perceptual Loss\n",
        "class VGGLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VGGLoss, self).__init__()\n",
        "        self.vgg = models.vgg16(pretrained=True).features[:16].eval()\n",
        "        for param in self.vgg.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        # Compute VGG features\n",
        "        vgg_output = self.vgg(output)\n",
        "        vgg_target = self.vgg(target)\n",
        "\n",
        "        # Compute L1 loss between features\n",
        "        return F.l1_loss(vgg_output, vgg_target)\n",
        "\n",
        "# Data Preparation\n",
        "def setup_data(root_dir='./data', img_size=128, batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((img_size, img_size)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Load CIFAR-10 dataset\n",
        "    dataset = datasets.CIFAR10(root=root_dir, train=True, download=True, transform=transform)\n",
        "\n",
        "    # Split into train, validation, and test sets\n",
        "    train_size = int(0.7 * len(dataset))\n",
        "    val_size = int(0.15 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "# Mask Generation\n",
        "def create_irregular_mask(image):\n",
        "    _, h, w = image.shape\n",
        "    mask = torch.ones_like(image)\n",
        "\n",
        "    # Randomly generate irregular shapes\n",
        "    for _ in range(np.random.randint(5, 10)):\n",
        "        mask_h = np.random.randint(h // 4, h // 2)\n",
        "        mask_w = np.random.randint(w // 4, w // 2)\n",
        "        top = np.random.randint(0, h - mask_h)\n",
        "        left = np.random.randint(0, w - mask_w)\n",
        "        mask[:, top:top+mask_h, left:left+mask_w] = 0\n",
        "\n",
        "    return mask\n",
        "\n",
        "# Training Loop\n",
        "def train_model(model, train_loader, val_loader, num_epochs=20, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "    criterion_vgg = VGGLoss().to(device)\n",
        "\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch_idx, batch in enumerate(train_loader):\n",
        "            images = batch[0].to(device)\n",
        "            masks = torch.stack([create_irregular_mask(img) for img in images]).to(device)\n",
        "            masked_images = images * masks\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(masked_images, masks)\n",
        "\n",
        "            # Compute losses\n",
        "            loss_l1 = criterion_l1(outputs, images)\n",
        "            loss_vgg = criterion_vgg(outputs, images)\n",
        "            loss = loss_l1 + 0.1 * loss_vgg  # Weighted combination\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            # Visualize intermediate results every 100 batches\n",
        "            if batch_idx % 100 == 0:\n",
        "                visualize_results(images, masked_images, outputs, epoch, batch_idx)\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                images = batch[0].to(device)\n",
        "                masks = torch.stack([create_irregular_mask(img) for img in images]).to(device)\n",
        "                masked_images = images * masks\n",
        "\n",
        "                outputs = model(masked_images, masks)\n",
        "                loss = criterion_l1(outputs, images)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        # Update learning rate\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
        "        print(f'Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
        "        print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
        "\n",
        "        # Save best model\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            torch.save(model.state_dict(), 'best_inpainting_model.pth')\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# Visualization Function\n",
        "def visualize_results(images, masked_images, outputs, epoch, batch_idx):\n",
        "    # Plot results without denormalization\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(images[0].cpu().permute(1, 2, 0))\n",
        "    plt.title('Original')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(masked_images[0].cpu().permute(1, 2, 0))\n",
        "    plt.title('Masked')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(outputs[0].cpu().permute(1, 2, 0))\n",
        "    plt.title('Inpainted')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.suptitle(f'Epoch {epoch+1}, Batch {batch_idx}')\n",
        "    plt.show()\n",
        "\n",
        "# Main Function\n",
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Load data\n",
        "    train_loader, val_loader, test_loader = setup_data(img_size=128, batch_size=32)\n",
        "\n",
        "    # Create and train model\n",
        "    model = InpaintingNet()\n",
        "    train_model(model, train_loader, val_loader, num_epochs=20, device=device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKjhX2Ar2_4f",
        "outputId": "e99fb2db-f0c7-4cb6-e0af-9de9397595c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▋      | 61.8M/170M [00:07<00:10, 9.88MB/s]"
          ]
        }
      ]
    }
  ]
}