{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjLlVFTkvlKa8Fa7v6wzP0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Image_Inpaint/blob/main/DCGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow pillow numpy matplotlib scikit-image opencv-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H5dL4aeBCqA",
        "outputId": "a84a3c3a-73e5-4bca-f762-d64c332f438d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.25.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.36.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.12.12)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will prompt you to upload your image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "DT57myGbBNpx",
        "outputId": "14cddcaa-e737-4498-bf26-e2eac1d776ba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cbe00f74-2bef-4ba0-a17d-225711251695\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-cbe00f74-2bef-4ba0-a17d-225711251695\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Mona_Lisa.jpg to Mona_Lisa.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GXGFTtWW2_sV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "11c3ccd9-ab72-4785-f1b0-623c8066c98e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generator Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m3,136\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_24 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m131,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_25 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m524,544\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_26 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_9 (\u001b[38;5;33mConv2DTranspose\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m524,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_27 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_10                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │         \u001b[38;5;34m131,136\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_28 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_11                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │           \u001b[38;5;34m3,075\u001b[0m │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)                    │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_10                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,136</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_transpose_11                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,075</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)                    │                             │                 │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,317,507\u001b[0m (5.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,317,507</span> (5.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,317,507\u001b[0m (5.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,317,507</span> (5.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Discriminator Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │           \u001b[38;5;34m3,136\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_29 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │         \u001b[38;5;34m131,200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_30 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │         \u001b[38;5;34m524,544\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_31 (\u001b[38;5;33mLeakyReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │         \u001b[38;5;34m262,145\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,136</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ leaky_re_lu_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">262,145</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m921,025\u001b[0m (3.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">921,025</span> (3.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m921,025\u001b[0m (3.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">921,025</span> (3.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training with 1 images for 100 epochs\n",
            "Epoch 0, Batch 0: Gen Loss = 0.0261, Disc Loss = 1.4115\n",
            "Epoch 1, Batch 0: Gen Loss = 0.1342, Disc Loss = 1.3560\n",
            "Epoch 2, Batch 0: Gen Loss = 0.0202, Disc Loss = 1.4758\n",
            "Epoch 3, Batch 0: Gen Loss = 0.0057, Disc Loss = 1.4129\n",
            "Epoch 4, Batch 0: Gen Loss = 0.1352, Disc Loss = 1.3653\n",
            "Epoch 5, Batch 0: Gen Loss = 0.0123, Disc Loss = 1.3983\n",
            "Epoch 6, Batch 0: Gen Loss = 0.0004, Disc Loss = 1.3978\n",
            "Epoch 7, Batch 0: Gen Loss = 0.0475, Disc Loss = 1.3806\n",
            "Epoch 8, Batch 0: Gen Loss = 0.0094, Disc Loss = 1.3778\n",
            "Epoch 9, Batch 0: Gen Loss = 0.0279, Disc Loss = 1.2779\n",
            "Epoch 10, Batch 0: Gen Loss = 0.1653, Disc Loss = 1.0809\n",
            "Epoch 11, Batch 0: Gen Loss = 0.0470, Disc Loss = 1.2076\n",
            "Epoch 12, Batch 0: Gen Loss = 0.1178, Disc Loss = 1.0106\n",
            "Epoch 13, Batch 0: Gen Loss = 0.1790, Disc Loss = 1.0261\n",
            "Epoch 14, Batch 0: Gen Loss = 0.1821, Disc Loss = 1.2251\n",
            "Epoch 15, Batch 0: Gen Loss = 0.0466, Disc Loss = 1.6092\n",
            "Epoch 16, Batch 0: Gen Loss = 0.0135, Disc Loss = 1.5421\n",
            "Epoch 17, Batch 0: Gen Loss = 0.0638, Disc Loss = 1.0444\n",
            "Epoch 18, Batch 0: Gen Loss = 0.0075, Disc Loss = 1.3569\n",
            "Epoch 19, Batch 0: Gen Loss = 0.1087, Disc Loss = 0.9713\n",
            "Epoch 20, Batch 0: Gen Loss = 0.1664, Disc Loss = 1.2720\n",
            "Epoch 21, Batch 0: Gen Loss = 0.0920, Disc Loss = 1.1285\n",
            "Epoch 22, Batch 0: Gen Loss = 0.0066, Disc Loss = 1.3937\n",
            "Epoch 23, Batch 0: Gen Loss = 0.0224, Disc Loss = 1.5031\n",
            "Epoch 24, Batch 0: Gen Loss = 0.0850, Disc Loss = 0.8773\n",
            "Epoch 25, Batch 0: Gen Loss = 0.0794, Disc Loss = 0.9355\n",
            "Epoch 26, Batch 0: Gen Loss = 0.0915, Disc Loss = 0.7402\n",
            "Epoch 27, Batch 0: Gen Loss = 0.0528, Disc Loss = 0.5855\n",
            "Epoch 28, Batch 0: Gen Loss = 0.0247, Disc Loss = 1.3650\n",
            "Epoch 29, Batch 0: Gen Loss = 0.0429, Disc Loss = 0.9202\n",
            "Epoch 30, Batch 0: Gen Loss = 0.1286, Disc Loss = 0.4428\n",
            "Epoch 31, Batch 0: Gen Loss = 0.0378, Disc Loss = 0.7879\n",
            "Epoch 32, Batch 0: Gen Loss = 0.0426, Disc Loss = 0.6176\n",
            "Epoch 33, Batch 0: Gen Loss = 0.0139, Disc Loss = 1.6199\n",
            "Epoch 34, Batch 0: Gen Loss = 0.0941, Disc Loss = 2.3264\n",
            "Epoch 35, Batch 0: Gen Loss = 0.0866, Disc Loss = 0.9240\n",
            "Epoch 36, Batch 0: Gen Loss = 0.1134, Disc Loss = 0.7672\n",
            "Epoch 37, Batch 0: Gen Loss = 0.0027, Disc Loss = 1.4959\n",
            "Epoch 38, Batch 0: Gen Loss = 0.0122, Disc Loss = 1.4560\n",
            "Epoch 39, Batch 0: Gen Loss = 0.0147, Disc Loss = 1.2987\n",
            "Epoch 40, Batch 0: Gen Loss = 0.0443, Disc Loss = 0.8670\n",
            "Epoch 41, Batch 0: Gen Loss = 0.0325, Disc Loss = 0.9759\n",
            "Epoch 42, Batch 0: Gen Loss = 0.0620, Disc Loss = 0.6942\n",
            "Epoch 43, Batch 0: Gen Loss = 0.0693, Disc Loss = 0.5573\n",
            "Epoch 44, Batch 0: Gen Loss = 0.0592, Disc Loss = 0.6393\n",
            "Epoch 45, Batch 0: Gen Loss = 0.0972, Disc Loss = 0.1938\n",
            "Epoch 46, Batch 0: Gen Loss = 0.0806, Disc Loss = 0.4573\n",
            "Epoch 47, Batch 0: Gen Loss = 0.0226, Disc Loss = 2.7424\n",
            "Epoch 48, Batch 0: Gen Loss = 0.0621, Disc Loss = 0.4042\n",
            "Epoch 49, Batch 0: Gen Loss = 0.0830, Disc Loss = 0.2523\n",
            "Epoch 50, Batch 0: Gen Loss = 0.0150, Disc Loss = 1.4142\n",
            "Epoch 51, Batch 0: Gen Loss = 0.0342, Disc Loss = 0.9414\n",
            "Epoch 52, Batch 0: Gen Loss = 0.0770, Disc Loss = 0.9660\n",
            "Epoch 53, Batch 0: Gen Loss = 0.0788, Disc Loss = 0.8867\n",
            "Epoch 54, Batch 0: Gen Loss = 0.0479, Disc Loss = 0.5752\n",
            "Epoch 55, Batch 0: Gen Loss = 0.0002, Disc Loss = 1.7593\n",
            "Epoch 56, Batch 0: Gen Loss = 0.0512, Disc Loss = 0.4470\n",
            "Epoch 57, Batch 0: Gen Loss = 0.0329, Disc Loss = 0.6018\n",
            "Epoch 58, Batch 0: Gen Loss = 0.0620, Disc Loss = 0.2064\n",
            "Epoch 59, Batch 0: Gen Loss = 0.0150, Disc Loss = 1.7167\n",
            "Epoch 60, Batch 0: Gen Loss = 0.0834, Disc Loss = 0.1971\n",
            "Epoch 61, Batch 0: Gen Loss = 0.0921, Disc Loss = 0.2379\n",
            "Epoch 62, Batch 0: Gen Loss = 0.1173, Disc Loss = 0.2500\n",
            "Epoch 63, Batch 0: Gen Loss = 0.0472, Disc Loss = 0.2873\n",
            "Epoch 64, Batch 0: Gen Loss = 0.0311, Disc Loss = 0.4127\n",
            "Epoch 65, Batch 0: Gen Loss = 0.0924, Disc Loss = 0.1412\n",
            "Epoch 66, Batch 0: Gen Loss = 0.0299, Disc Loss = 0.6480\n",
            "Epoch 67, Batch 0: Gen Loss = 0.0507, Disc Loss = 0.1753\n",
            "Epoch 68, Batch 0: Gen Loss = 0.0056, Disc Loss = 2.2647\n",
            "Epoch 69, Batch 0: Gen Loss = 0.0432, Disc Loss = 0.2375\n",
            "Epoch 70, Batch 0: Gen Loss = 0.0083, Disc Loss = 1.2963\n",
            "Epoch 71, Batch 0: Gen Loss = 0.0214, Disc Loss = 0.7667\n",
            "Epoch 72, Batch 0: Gen Loss = 0.0810, Disc Loss = 0.8686\n",
            "Epoch 73, Batch 0: Gen Loss = 0.0017, Disc Loss = 1.2855\n",
            "Epoch 74, Batch 0: Gen Loss = 0.0613, Disc Loss = 0.4868\n",
            "Epoch 75, Batch 0: Gen Loss = 0.0308, Disc Loss = 0.3221\n",
            "Epoch 76, Batch 0: Gen Loss = 0.0005, Disc Loss = 2.4176\n",
            "Epoch 77, Batch 0: Gen Loss = 0.0260, Disc Loss = 1.0572\n",
            "Epoch 78, Batch 0: Gen Loss = 0.0309, Disc Loss = 0.3583\n",
            "Epoch 79, Batch 0: Gen Loss = 0.0687, Disc Loss = 0.3067\n",
            "Epoch 80, Batch 0: Gen Loss = 0.0091, Disc Loss = 1.1885\n",
            "Epoch 81, Batch 0: Gen Loss = 0.0117, Disc Loss = 0.7467\n",
            "Epoch 82, Batch 0: Gen Loss = 0.0176, Disc Loss = 0.6021\n",
            "Epoch 83, Batch 0: Gen Loss = 0.0005, Disc Loss = 1.5048\n",
            "Epoch 84, Batch 0: Gen Loss = 0.0375, Disc Loss = 0.5177\n",
            "Epoch 85, Batch 0: Gen Loss = 0.0439, Disc Loss = 0.5229\n",
            "Epoch 86, Batch 0: Gen Loss = 0.0005, Disc Loss = 1.7510\n",
            "Epoch 87, Batch 0: Gen Loss = 0.0335, Disc Loss = 0.2937\n",
            "Epoch 88, Batch 0: Gen Loss = 0.0016, Disc Loss = 1.6902\n",
            "Epoch 89, Batch 0: Gen Loss = 0.0269, Disc Loss = 0.5826\n",
            "Epoch 90, Batch 0: Gen Loss = 0.0088, Disc Loss = 1.2616\n",
            "Epoch 91, Batch 0: Gen Loss = 0.0662, Disc Loss = 0.6952\n",
            "Epoch 92, Batch 0: Gen Loss = 0.0313, Disc Loss = 0.5907\n",
            "Epoch 93, Batch 0: Gen Loss = 0.0119, Disc Loss = 0.8401\n",
            "Epoch 94, Batch 0: Gen Loss = 0.0155, Disc Loss = 1.3172\n",
            "Epoch 95, Batch 0: Gen Loss = 0.0188, Disc Loss = 0.7248\n",
            "Epoch 96, Batch 0: Gen Loss = 0.0586, Disc Loss = 0.2683\n",
            "Epoch 97, Batch 0: Gen Loss = 0.0114, Disc Loss = 0.7577\n",
            "Epoch 98, Batch 0: Gen Loss = 0.0731, Disc Loss = 0.2975\n",
            "Epoch 99, Batch 0: Gen Loss = 0.0054, Disc Loss = 1.6419\n",
            "Evaluation error: win_size exceeds image extent. Either ensure that your images are at least 7x7; or pass win_size explicitly in the function call, with an odd value less than or equal to the smaller side of your images. If your images are multichannel (with color channels), set channel_axis to the axis number corresponding to the channels.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# Step 1: Load and prepare data\n",
        "def load_image(image_path, size=(256, 256)):\n",
        "    \"\"\"Load and resize image\"\"\"\n",
        "    img = Image.open(image_path)\n",
        "    img = img.resize(size)\n",
        "    img = np.array(img) / 255.0  # Normalize to [0,1]\n",
        "    return img\n",
        "\n",
        "def load_dataset(directory, size=(256, 256)):\n",
        "    \"\"\"Load all images from directory\"\"\"\n",
        "    images = []\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith((\".png\", \".jpg\", \".jpeg\")):\n",
        "            img_path = os.path.join(directory, filename)\n",
        "            img = load_image(img_path, size)\n",
        "            images.append(img)\n",
        "    return np.array(images)\n",
        "\n",
        "# Step 2: Preprocess images\n",
        "def preprocess_images(images):\n",
        "    \"\"\"Preprocess images for the model\"\"\"\n",
        "    # Convert to float32\n",
        "    images = images.astype('float32')\n",
        "    # Ensure values are in [-1, 1]\n",
        "    images = (images * 2) - 1\n",
        "    return images\n",
        "\n",
        "# Step 3: Create mask\n",
        "def create_random_mask(shape, max_boxes=5):\n",
        "    \"\"\"Create random rectangular masks\"\"\"\n",
        "    mask = np.ones(shape, dtype=np.float32)  # Specify dtype as float32\n",
        "    for _ in range(np.random.randint(1, max_boxes)):\n",
        "        x1, x2 = sorted(np.random.randint(0, shape[1], 2))\n",
        "        y1, y2 = sorted(np.random.randint(0, shape[0], 2))\n",
        "        mask[y1:y2, x1:x2] = 0\n",
        "    return mask\n",
        "\n",
        "# Step 4: Define Generator and Discriminator\n",
        "def build_generator():\n",
        "    \"\"\"Create the generator model\"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        # Encoder\n",
        "        layers.Input(shape=(256, 256, 3)),\n",
        "        layers.Conv2D(64, 4, strides=2, padding='same'),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Conv2D(128, 4, strides=2, padding='same'),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Conv2D(256, 4, strides=2, padding='same'),\n",
        "        layers.LeakyReLU(0.2),\n",
        "\n",
        "        # Decoder\n",
        "        layers.Conv2DTranspose(128, 4, strides=2, padding='same'),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Conv2DTranspose(64, 4, strides=2, padding='same'),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Conv2DTranspose(3, 4, strides=2, padding='same', activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator():\n",
        "    \"\"\"Create the discriminator model\"\"\"\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Input(shape=(256, 256, 3)),\n",
        "        layers.Conv2D(64, 4, strides=2, padding='same'),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Conv2D(128, 4, strides=2, padding='same'),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Conv2D(256, 4, strides=2, padding='same'),\n",
        "        layers.LeakyReLU(0.2),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Step 5: Combine into DCGAN\n",
        "class DCGAN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(DCGAN, self).__init__()\n",
        "        self.generator = build_generator()\n",
        "        self.discriminator = build_discriminator()\n",
        "\n",
        "        # Optimizers\n",
        "        self.gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "        self.disc_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "        # Loss\n",
        "        self.cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "        self.mse = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, images, masks):\n",
        "        \"\"\"Single training step\"\"\"\n",
        "        batch_size = tf.shape(images)[0]\n",
        "\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            # Generate images\n",
        "            masked_images = images * masks\n",
        "            generated_images = self.generator(masked_images, training=True)\n",
        "\n",
        "            # Combine real and generated images\n",
        "            filled_images = masked_images + (1 - masks) * generated_images\n",
        "\n",
        "            # Train discriminator\n",
        "            real_output = self.discriminator(images, training=True)\n",
        "            fake_output = self.discriminator(filled_images, training=True)\n",
        "\n",
        "            # Calculate losses\n",
        "            gen_loss = self.mse(images, filled_images)\n",
        "            disc_loss = self.cross_entropy(tf.ones_like(real_output), real_output) + \\\n",
        "                       self.cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "\n",
        "        # Apply gradients\n",
        "        gen_gradients = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "        disc_gradients = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "        self.gen_optimizer.apply_gradients(zip(gen_gradients, self.generator.trainable_variables))\n",
        "        self.disc_optimizer.apply_gradients(zip(disc_gradients, self.discriminator.trainable_variables))\n",
        "\n",
        "        return gen_loss, disc_loss\n",
        "\n",
        "# Step 6: Training function\n",
        "def train_model(model, dataset, epochs=100, batch_size=1):\n",
        "    \"\"\"Train the model\"\"\"\n",
        "    print(f\"Starting training with {len(dataset)} images for {epochs} epochs\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for batch in range(0, len(dataset), batch_size):\n",
        "            # Get batch of images\n",
        "            batch_images = dataset[batch:batch + batch_size]\n",
        "\n",
        "            # Create masks for this batch\n",
        "            masks = np.stack([create_random_mask((256, 256)) for _ in range(len(batch_images))])\n",
        "            masks = np.expand_dims(masks, axis=-1)\n",
        "            masks = np.repeat(masks, 3, axis=-1)\n",
        "\n",
        "            # Convert masks to float32\n",
        "            masks = tf.cast(masks, tf.float32)\n",
        "            # Ensure images are float32\n",
        "            batch_images = tf.cast(batch_images, tf.float32)\n",
        "\n",
        "            # Train on batch\n",
        "            try:\n",
        "                gen_loss, disc_loss = model.train_step(batch_images, masks)\n",
        "                if batch % 10 == 0:\n",
        "                    print(f\"Epoch {epoch}, Batch {batch}: Gen Loss = {gen_loss:.4f}, Disc Loss = {disc_loss:.4f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error in batch {batch}: {str(e)}\")\n",
        "                raise e\n",
        "# Step 7: Evaluation functions\n",
        "def evaluate_model(model, test_image, test_mask):\n",
        "    \"\"\"Evaluate model on a single test image\"\"\"\n",
        "    # Generate inpainted image\n",
        "    masked_image = test_image * test_mask\n",
        "    generated = model.generator(np.expand_dims(masked_image, 0), training=False)\n",
        "    generated = generated[0].numpy()\n",
        "\n",
        "    # Combine masked and generated portions\n",
        "    inpainted = masked_image + (1 - test_mask) * generated\n",
        "\n",
        "    # Calculate metrics\n",
        "    psnr_value = psnr(test_image, inpainted)\n",
        "    ssim_value = ssim(test_image, inpainted, multichannel=True)\n",
        "\n",
        "    return inpainted, psnr_value, ssim_value\n",
        "\n",
        "# Step 8: Visualization function\n",
        "def visualize_results(original, masked, inpainted):\n",
        "    \"\"\"Visualize original, masked, and inpainted images\"\"\"\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axes[0].imshow(original)\n",
        "    axes[0].set_title('Original')\n",
        "    axes[0].axis('off')\n",
        "\n",
        "    axes[1].imshow(masked)\n",
        "    axes[1].set_title('Masked')\n",
        "    axes[1].axis('off')\n",
        "\n",
        "    axes[2].imshow(inpainted)\n",
        "    axes[2].set_title('Inpainted')\n",
        "    axes[2].axis('off')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def main():\n",
        "    # Load dataset\n",
        "    # Load the single image\n",
        "    image_path = \"Mona_Lisa.jpg\"  # Updated path\n",
        "\n",
        "    # Ensure the file exists\n",
        "    if not os.path.exists(image_path):\n",
        "        raise FileNotFoundError(f\"Could not find image at {image_path}\")\n",
        "\n",
        "    # Load and prepare single image\n",
        "    image = load_image(image_path)\n",
        "    images = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    images = preprocess_images(images)\n",
        "\n",
        "    # Create and train model\n",
        "    model = DCGAN()\n",
        "\n",
        "    # Print model summary to verify architecture\n",
        "    print(\"Generator Summary:\")\n",
        "    model.generator.summary()\n",
        "    print(\"\\nDiscriminator Summary:\")\n",
        "    model.discriminator.summary()\n",
        "\n",
        "    # Train with error handling\n",
        "    try:\n",
        "        train_model(model, images, epochs=100, batch_size=1)  # Use batch_size=1 since we have one image\n",
        "    except Exception as e:\n",
        "        print(f\"Training error: {str(e)}\")\n",
        "        return\n",
        "\n",
        "    # Evaluate on test image\n",
        "    try:\n",
        "        test_image = load_image(image_path)\n",
        "        test_mask = create_random_mask((256, 256))\n",
        "        test_mask = np.expand_dims(test_mask, axis=-1)\n",
        "        test_mask = np.repeat(test_mask, 3, axis=-1)\n",
        "\n",
        "        # Get results\n",
        "        inpainted, psnr_value, ssim_value = evaluate_model(model, test_image, test_mask)\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"PSNR: {psnr_value:.2f}\")\n",
        "        print(f\"SSIM: {ssim_value:.2f}\")\n",
        "\n",
        "        # Visualize results\n",
        "        masked_image = test_image * test_mask\n",
        "        visualize_results(test_image, masked_image, inpainted)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Evaluation error: {str(e)}\")\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2fvhXPLd91nm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}