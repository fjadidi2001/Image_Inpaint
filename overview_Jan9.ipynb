{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPfVCAjQIrMWfZuw0h388iO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Image_Inpaint/blob/main/overview_Jan9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q\n"
      ],
      "metadata": {
        "id": "r0lTwcWX6dha"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset,random_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "YuvuTkDWAG3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"places-xlstm-1\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "CHECKPOINTS_DIR = '/content/drive/MyDrive/ckpts'\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch):\n",
        "    os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
        "    checkpoint_path = f'{CHECKPOINTS_DIR}/{model_name}.pth'\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "    print(f\"ckpt saved for {model_name} at epoch {epoch}.\")\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "    ckpt_path = f'{CHECKPOINTS_DIR}/{model_name}.pth'\n",
        "    if not os.path.exists(ckpt_path):\n",
        "        print(f\"no ckpt found for {model_name} starting from epoch 0.\")\n",
        "        return 0\n",
        "\n",
        "    checkpoint = torch.load(ckpt_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"ckpt loaded for {model_name} from {ckpt_path}. resuming from epoch {start_epoch}.\")\n",
        "\n",
        "    return start_epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2057pAhVZPJ",
        "outputId": "7eff2f0c-bf1f-4a12-a5e4-a9e0e407fb6d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jessicali9530/caltech256\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhJj29sXQPgs",
        "outputId": "21b8ebb1-73ee-4d5d-b223-6ad8d9e8d9f0"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/jessicali9530/caltech256?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.12G/2.12G [01:18<00:00, 28.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/jessicali9530/caltech256/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "from torchvision import transforms\n",
        "\n",
        "def visualize_random_images(data_path, num_images=5):\n",
        "    \"\"\"\n",
        "    Visualize random images from the dataset\n",
        "    \"\"\"\n",
        "    # Get all image paths\n",
        "    image_paths = []\n",
        "    for root, dirs, files in os.walk(data_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "\n",
        "    # Select random images\n",
        "    selected_images = random.sample(image_paths, min(num_images, len(image_paths)))\n",
        "\n",
        "    # Create subplot\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 3))\n",
        "\n",
        "    for idx, img_path in enumerate(selected_images):\n",
        "        img = Image.open(img_path)\n",
        "        axes[idx].imshow(img)\n",
        "        axes[idx].axis('off')\n",
        "        axes[idx].set_title(f'Image {idx+1}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def create_random_mask(size, mask_ratio=0.2):\n",
        "    \"\"\"\n",
        "    Create a random rectangular mask\n",
        "    \"\"\"\n",
        "    height, width = size\n",
        "    mask = np.ones((height, width), np.float32)\n",
        "\n",
        "    # Calculate random rectangle dimensions\n",
        "    mask_height = int(height * np.sqrt(mask_ratio))\n",
        "    mask_width = int(width * np.sqrt(mask_ratio))\n",
        "\n",
        "    # Calculate random position\n",
        "    top = random.randint(0, height - mask_height)\n",
        "    left = random.randint(0, width - mask_width)\n",
        "\n",
        "    # Apply mask\n",
        "    mask[top:top + mask_height, left:left + width_mask] = 0\n",
        "    return mask\n",
        "\n",
        "def process_and_visualize_masked_images(data_path, num_samples=5, target_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Process images with masks and visualize results\n",
        "    \"\"\"\n",
        "    # Get image paths\n",
        "    image_paths = []\n",
        "    for root, dirs, files in os.walk(data_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "\n",
        "    # Select random images\n",
        "    selected_images = random.sample(image_paths, min(num_samples, len(image_paths)))\n",
        "\n",
        "    # Setup transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(target_size),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Create visualization grid\n",
        "    fig, axes = plt.subplots(3, num_samples, figsize=(15, 8))\n",
        "\n",
        "    for idx, img_path in enumerate(selected_images):\n",
        "        # Load and transform image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img_tensor = transform(img)\n",
        "\n",
        "        # Create mask\n",
        "        mask = create_random_mask(target_size)\n",
        "        mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
        "\n",
        "        # Apply mask to image\n",
        "        masked_img = img_tensor * mask_tensor\n",
        "\n",
        "        # Convert tensors back to numpy for visualization\n",
        "        orig_img = img_tensor.permute(1, 2, 0).numpy()\n",
        "        mask_viz = mask_tensor.permute(1, 2, 0).numpy()\n",
        "        masked_img = masked_img.permute(1, 2, 0).numpy()\n",
        "\n",
        "        # Plot\n",
        "        axes[0, idx].imshow(orig_img)\n",
        "        axes[0, idx].axis('off')\n",
        "        axes[0, idx].set_title('Original')\n",
        "\n",
        "        axes[1, idx].imshow(mask_viz, cmap='gray')\n",
        "        axes[1, idx].axis('off')\n",
        "        axes[1, idx].set_title('Mask')\n",
        "\n",
        "        axes[2, idx].imshow(masked_img)\n",
        "        axes[2, idx].axis('off')\n",
        "        axes[2, idx].set_title('Masked')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def create_masked_dataset(data_path, num_images=1000, target_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Create a dataset of original and masked images\n",
        "    \"\"\"\n",
        "    # Get all image paths\n",
        "    image_paths = []\n",
        "    for root, dirs, files in os.walk(data_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "\n",
        "    # Select random images\n",
        "    selected_images = random.sample(image_paths, min(num_images, len(image_paths)))\n",
        "\n",
        "    # Setup transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(target_size),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    dataset = []\n",
        "    for img_path in selected_images:\n",
        "        # Load and transform image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img_tensor = transform(img)\n",
        "\n",
        "        # Create mask\n",
        "        mask = create_random_mask(target_size)\n",
        "        mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
        "\n",
        "        # Apply mask to image\n",
        "        masked_img = img_tensor * mask_tensor\n",
        "\n",
        "        dataset.append({\n",
        "            'original': img_tensor,\n",
        "            'masked': masked_img,\n",
        "            'mask': mask_tensor\n",
        "        })\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "pzXAGwXIRHNt"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}