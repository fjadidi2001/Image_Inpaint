{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMNVaj7jwyMcs5As+36m1RM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Image_Inpaint/blob/main/overview_Jan9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets -q\n"
      ],
      "metadata": {
        "id": "r0lTwcWX6dha"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset,random_split\n",
        "from datasets import Dataset, DatasetDict\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "YuvuTkDWAG3S"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name=\"caltech256-xlstm\"\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "CHECKPOINTS_DIR = '/content/drive/MyDrive/ckpts'\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch):\n",
        "    os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
        "    checkpoint_path = f'{CHECKPOINTS_DIR}/{model_name}.pth'\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }, checkpoint_path)\n",
        "    print(f\"ckpt saved for {model_name} at epoch {epoch}.\")\n",
        "\n",
        "def load_checkpoint(model, optimizer):\n",
        "    ckpt_path = f'{CHECKPOINTS_DIR}/{model_name}.pth'\n",
        "    if not os.path.exists(ckpt_path):\n",
        "        print(f\"no ckpt found for {model_name} starting from epoch 0.\")\n",
        "        return 0\n",
        "\n",
        "    checkpoint = torch.load(ckpt_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"ckpt loaded for {model_name} from {ckpt_path}. resuming from epoch {start_epoch}.\")\n",
        "\n",
        "    return start_epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2057pAhVZPJ",
        "outputId": "ddf5ebc1-a938-4d00-a42a-0e3336d1f575"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"jessicali9530/caltech256\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhJj29sXQPgs",
        "outputId": "b2b7a853-336d-4a73-e341-34c2e9b5ebc9"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/jessicali9530/caltech256/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import glob\n",
        "from torchvision import transforms\n",
        "\n",
        "def set_style():\n",
        "    \"\"\"Set the style for prettier visualizations\"\"\"\n",
        "    plt.style.use('default')  # Using default style instead of seaborn\n",
        "    plt.rcParams['figure.facecolor'] = 'white'\n",
        "    plt.rcParams['axes.facecolor'] = 'white'\n",
        "    plt.rcParams['figure.dpi'] = 150\n",
        "\n",
        "def create_random_mask(size, mask_ratio=0.05):  # Reduced mask ratio to 5%\n",
        "    \"\"\"\n",
        "    Create multiple small random masks\n",
        "    \"\"\"\n",
        "    height, width = size\n",
        "    mask = np.ones((height, width), np.float32)\n",
        "\n",
        "    # Create 2-4 small masks instead of one large mask\n",
        "    num_masks = random.randint(2, 4)\n",
        "\n",
        "    for _ in range(num_masks):\n",
        "        # Calculate small rectangle dimensions\n",
        "        mask_height = int(height * np.sqrt(mask_ratio))\n",
        "        mask_width = int(width * np.sqrt(mask_ratio))\n",
        "\n",
        "        # Make masks even smaller with random scaling\n",
        "        scale = random.uniform(0.3, 0.7)\n",
        "        mask_height = int(mask_height * scale)\n",
        "        mask_width = int(mask_width * scale)\n",
        "\n",
        "        # Calculate random position\n",
        "        top = random.randint(0, height - mask_height)\n",
        "        left = random.randint(0, width - mask_width)\n",
        "\n",
        "        # Apply mask\n",
        "        mask[top:top + mask_height, left:left + mask_width] = 0\n",
        "\n",
        "    return mask\n",
        "\n",
        "def process_and_visualize_masked_images(data_path, num_samples=5, target_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Process images with masks and visualize results with enhanced styling\n",
        "    \"\"\"\n",
        "    # Set the style\n",
        "    set_style()\n",
        "\n",
        "    # Get image paths\n",
        "    image_paths = []\n",
        "    for root, dirs, files in os.walk(data_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "\n",
        "    # Select random images\n",
        "    selected_images = random.sample(image_paths, min(num_samples, len(image_paths)))\n",
        "\n",
        "    # Setup transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(target_size),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    # Create figure with better spacing\n",
        "    fig = plt.figure(figsize=(20, 4))\n",
        "    plt.subplots_adjust(wspace=0.3)\n",
        "\n",
        "    for idx, img_path in enumerate(selected_images):\n",
        "        # Load and transform image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img_tensor = transform(img)\n",
        "\n",
        "        # Create mask\n",
        "        mask = create_random_mask(target_size)\n",
        "        mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
        "\n",
        "        # Apply mask to image\n",
        "        masked_img = img_tensor * mask_tensor\n",
        "\n",
        "        # Convert tensors back to numpy for visualization\n",
        "        orig_img = img_tensor.permute(1, 2, 0).numpy()\n",
        "        mask_viz = mask_tensor.permute(1, 2, 0).numpy()\n",
        "        masked_img = masked_img.permute(1, 2, 0).numpy()\n",
        "\n",
        "        # Create subplots in a vertical arrangement\n",
        "        ax1 = plt.subplot(3, num_samples, idx + 1)\n",
        "        ax2 = plt.subplot(3, num_samples, idx + 1 + num_samples)\n",
        "        ax3 = plt.subplot(3, num_samples, idx + 1 + 2*num_samples)\n",
        "\n",
        "        # Plot with enhanced styling\n",
        "        ax1.imshow(orig_img)\n",
        "        ax1.set_title('Original', pad=5)\n",
        "\n",
        "        ax2.imshow(mask_viz, cmap='cool')  # Changed mask colormap\n",
        "        ax2.set_title('Mask', pad=5)\n",
        "\n",
        "        ax3.imshow(masked_img)\n",
        "        ax3.set_title('Masked', pad=5)\n",
        "\n",
        "        # Remove axes for cleaner look\n",
        "        for ax in [ax1, ax2, ax3]:\n",
        "            ax.set_xticks([])\n",
        "            ax.set_yticks([])\n",
        "            ax.spines['top'].set_visible(False)\n",
        "            ax.spines['right'].set_visible(False)\n",
        "            ax.spines['bottom'].set_visible(False)\n",
        "            ax.spines['left'].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def create_masked_dataset(data_path, num_images=1000, target_size=(256, 256)):\n",
        "    \"\"\"\n",
        "    Create a dataset of original and masked images\n",
        "    \"\"\"\n",
        "    # Get all image paths\n",
        "    image_paths = []\n",
        "    for root, dirs, files in os.walk(data_path):\n",
        "        for file in files:\n",
        "            if file.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                image_paths.append(os.path.join(root, file))\n",
        "\n",
        "    # Select random images\n",
        "    selected_images = random.sample(image_paths, min(num_images, len(image_paths)))\n",
        "\n",
        "    # Setup transforms\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize(target_size),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    dataset = []\n",
        "    for img_path in selected_images:\n",
        "        # Load and transform image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img_tensor = transform(img)\n",
        "\n",
        "        # Create mask\n",
        "        mask = create_random_mask(target_size)\n",
        "        mask_tensor = torch.from_numpy(mask).unsqueeze(0)\n",
        "\n",
        "        # Apply mask to image\n",
        "        masked_img = img_tensor * mask_tensor\n",
        "\n",
        "        dataset.append({\n",
        "            'original': img_tensor,\n",
        "            'masked': masked_img,\n",
        "            'mask': mask_tensor\n",
        "        })\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "_SDCB7nybHIj"
      },
      "execution_count": 63,
      "outputs": []
    }
  ]
}