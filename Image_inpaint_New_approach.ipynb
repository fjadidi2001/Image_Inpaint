{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjadidi2001/Image_Inpaint/blob/main/Image_inpaint_New_approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import gc\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Enable memory growth for GPU\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# Configuration\n",
        "IMG_SIZE = 128  # Reduced from 256 due to memory constraints\n",
        "BATCH_SIZE = 4\n",
        "BUFFER_SIZE = 1000\n",
        "DATA_DIR = \"celeba_hq_256\"\n",
        "\n",
        "def load_and_analyze_dataset():\n",
        "    \"\"\"Load images and perform EDA\"\"\"\n",
        "    image_paths = [os.path.join(DATA_DIR, f) for f in os.listdir(DATA_DIR) if f.endswith(('.jpg', '.png'))]\n",
        "    print(f\"Total images found: {len(image_paths)}\")\n",
        "\n",
        "    # Sample images for analysis\n",
        "    sample_size = min(1000, len(image_paths))\n",
        "    sample_paths = random.sample(image_paths, sample_size)\n",
        "\n",
        "    # Analyze image properties\n",
        "    sizes = []\n",
        "    channels = []\n",
        "    pixel_values = []\n",
        "\n",
        "    for path in tqdm(sample_paths[:100]):  # Analyze first 100 images\n",
        "        img = cv2.imread(path)\n",
        "        sizes.append(img.shape[:2])\n",
        "        channels.append(img.shape[2])\n",
        "        pixel_values.extend(img.ravel())\n",
        "\n",
        "    # Create visualizations\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(131)\n",
        "    plt.hist(pixel_values, bins=50)\n",
        "    plt.title('Pixel Value Distribution')\n",
        "\n",
        "    plt.subplot(132)\n",
        "    sizes_np = np.array(sizes)\n",
        "    plt.scatter(sizes_np[:, 0], sizes_np[:, 1])\n",
        "    plt.title('Image Dimensions')\n",
        "\n",
        "    plt.subplot(133)\n",
        "    plt.hist(channels)\n",
        "    plt.title('Number of Channels')\n",
        "    plt.show()\n",
        "\n",
        "    return image_paths\n",
        "\n",
        "def create_mask(height, width):\n",
        "    \"\"\"Create random masks for inpainting\"\"\"\n",
        "    mask = np.ones((height, width, 1))\n",
        "\n",
        "    # Random rectangular mask\n",
        "    y1, x1 = np.random.randint(0, height - height//3), np.random.randint(0, width - width//3)\n",
        "    h, w = height//3, width//3\n",
        "    mask[y1:y1+h, x1:x1+w] = 0\n",
        "\n",
        "    return mask\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Load and preprocess images\"\"\"\n",
        "    img = tf.io.read_file(image_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "    img = tf.cast(img, tf.float32) / 255.0\n",
        "\n",
        "    mask = create_mask(IMG_SIZE, IMG_SIZE)\n",
        "    masked_img = img * mask\n",
        "\n",
        "    return masked_img, mask, img\n",
        "\n",
        "def create_dataset(image_paths):\n",
        "    \"\"\"Create TensorFlow dataset\"\"\"\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    dataset = dataset.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "    return dataset\n",
        "\n",
        "def unet_model():\n",
        "    \"\"\"Create U-Net model\"\"\"\n",
        "    inputs = layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Bridge\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
        "\n",
        "    # Decoder\n",
        "    up1 = layers.UpSampling2D(size=(2, 2))(conv3)\n",
        "    up1 = layers.concatenate([conv2, up1], axis=-1)\n",
        "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same')(up1)\n",
        "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
        "\n",
        "    up2 = layers.UpSampling2D(size=(2, 2))(conv4)\n",
        "    up2 = layers.concatenate([conv1, up2], axis=-1)\n",
        "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same')(up2)\n",
        "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    outputs = layers.Conv2D(3, 1, activation='sigmoid')(conv5)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "def hint_model():\n",
        "    \"\"\"Create HINT model with transformer architecture\"\"\"\n",
        "    inputs = layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    mask_input = layers.Input((IMG_SIZE, IMG_SIZE, 1))\n",
        "\n",
        "    # Encode input with mask awareness\n",
        "    x = layers.concatenate([inputs, mask_input])\n",
        "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "\n",
        "    # Transformer blocks\n",
        "    for _ in range(3):\n",
        "        # Multi-head attention\n",
        "        attention = layers.MultiHeadAttention(num_heads=4, key_dim=16)(x, x)\n",
        "        x = layers.Add()([attention, x])\n",
        "        x = layers.LayerNormalization()(x)\n",
        "\n",
        "        # FFN\n",
        "        ffn = layers.Dense(128, activation='relu')(x)\n",
        "        ffn = layers.Dense(64)(ffn)\n",
        "        x = layers.Add()([ffn, x])\n",
        "        x = layers.LayerNormalization()(x)\n",
        "\n",
        "    outputs = layers.Conv2D(3, 1, activation='sigmoid')(x)\n",
        "\n",
        "    return Model(inputs=[inputs, mask_input], outputs=outputs)\n",
        "\n",
        "def combined_model(unet, hint):\n",
        "    \"\"\"Combine U-Net and HINT models\"\"\"\n",
        "    inputs = layers.Input((IMG_SIZE, IMG_SIZE, 3))\n",
        "    mask_input = layers.Input((IMG_SIZE, IMG_SIZE, 1))\n",
        "\n",
        "    unet_output = unet(inputs)\n",
        "    hint_output = hint([inputs, mask_input])\n",
        "\n",
        "    combined = layers.Average()([unet_output, hint_output])\n",
        "\n",
        "    return Model(inputs=[inputs, mask_input], outputs=combined)\n",
        "\n",
        "def evaluate_models(models, test_dataset):\n",
        "    \"\"\"Evaluate models using various metrics\"\"\"\n",
        "    metrics = {\n",
        "        'PSNR': [],\n",
        "        'SSIM': [],\n",
        "        'L1_Loss': []\n",
        "    }\n",
        "\n",
        "    for model_name, model in models.items():\n",
        "        psnr_values = []\n",
        "        ssim_values = []\n",
        "        l1_values = []\n",
        "\n",
        "        for masked_imgs, masks, original_imgs in test_dataset:\n",
        "            if isinstance(model.input, list):\n",
        "                predictions = model([masked_imgs, masks])\n",
        "            else:\n",
        "                predictions = model(masked_imgs)\n",
        "\n",
        "            # Calculate metrics\n",
        "            psnr = tf.image.psnr(original_imgs, predictions, max_val=1.0)\n",
        "            ssim = tf.image.ssim(original_imgs, predictions, max_val=1.0)\n",
        "            l1 = tf.reduce_mean(tf.abs(original_imgs - predictions))\n",
        "\n",
        "            psnr_values.extend(psnr.numpy())\n",
        "            ssim_values.extend(ssim.numpy())\n",
        "            l1_values.append(l1.numpy())\n",
        "\n",
        "        metrics['PSNR'].append(np.mean(psnr_values))\n",
        "        metrics['SSIM'].append(np.mean(ssim_values))\n",
        "        metrics['L1_Loss'].append(np.mean(l1_values))\n",
        "\n",
        "    # Visualize metrics\n",
        "    df = pd.DataFrame(metrics, index=list(models.keys()))\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(data=df)\n",
        "    plt.title('Model Comparison')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    # 1. Load dataset and perform EDA\n",
        "    image_paths = load_and_analyze_dataset()\n",
        "\n",
        "    # 2. Split dataset\n",
        "    train_paths, test_paths = train_test_split(image_paths, test_size=0.2, random_state=42)\n",
        "\n",
        "    # 3. Create datasets\n",
        "    train_dataset = create_dataset(train_paths)\n",
        "    test_dataset = create_dataset(test_paths)\n",
        "\n",
        "    # 4. Create models\n",
        "    unet = unet_model()\n",
        "    hint = hint_model()\n",
        "    combined = combined_model(unet, hint)\n",
        "\n",
        "    # 5. Compile models\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    loss = 'mse'\n",
        "\n",
        "    unet.compile(optimizer=optimizer, loss=loss)\n",
        "    hint.compile(optimizer=optimizer, loss=loss)\n",
        "    combined.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "    # 6. Train models (showing only structure here due to computational constraints)\n",
        "    print(\"Models created and compiled successfully\")\n",
        "\n",
        "    # 7. Evaluate models\n",
        "    models = {\n",
        "        'U-Net': unet,\n",
        "        'HINT': hint,\n",
        "        'Combined': combined\n",
        "    }\n",
        "\n",
        "    results = evaluate_models(models, test_dataset)\n",
        "    print(\"\\nEvaluation Results:\")\n",
        "    print(results)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "TjPkBht2heVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "f77bdbde-345e-4e4f-fe9e-9914722e0ae2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'celeba_hq_256'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-063f4cf07f4f>\u001b[0m in \u001b[0;36m<cell line: 245>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-063f4cf07f4f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;31m# 1. Load dataset and perform EDA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_analyze_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;31m# 2. Split dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-063f4cf07f4f>\u001b[0m in \u001b[0;36mload_and_analyze_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_analyze_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;34m\"\"\"Load images and perform EDA\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Total images found: {len(image_paths)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'celeba_hq_256'"
          ]
        }
      ]
    }
  ]
}